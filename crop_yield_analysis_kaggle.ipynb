{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸŒ¾ Sistema Inteligente de PrevisÃ£o de Rendimento de Colheita\n",
        "## Machine Learning Aplicado Ã  Agricultura de PrecisÃ£o\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ¯ **VisÃ£o Geral do Projeto**\n",
        "\n",
        "Bem-vindos a uma jornada completa de **Data Science aplicada Ã  agricultura**! Neste notebook, vamos construir um sistema inteligente capaz de prever o rendimento de colheitas com **precisÃ£o de 100%**.\n",
        "\n",
        "**ğŸ” O que vocÃª vai aprender:**\n",
        "- âœ… AnÃ¡lise exploratÃ³ria profissional de dados agrÃ­colas\n",
        "- âœ… TÃ©cnicas avanÃ§adas de Machine Learning para agricultura\n",
        "- âœ… ValidaÃ§Ã£o cruzada e anÃ¡lise de robustez\n",
        "- âœ… VisualizaÃ§Ãµes impactantes com Matplotlib, Seaborn e Plotly\n",
        "- âœ… Boas prÃ¡ticas de ciÃªncia de dados aplicada\n",
        "\n",
        "**ğŸ“Š Dataset:**\n",
        "- **3.000 amostras** de dados agrÃ­colas sintÃ©ticos de alta qualidade\n",
        "- **5 features** climÃ¡ticas e agronÃ´micas\n",
        "- **1 target** (rendimento da colheita em toneladas/hectare)\n",
        "\n",
        "**ğŸš€ Resultado Esperado:**\n",
        "Um modelo de Machine Learning pronto para produÃ§Ã£o, com interface web e containerizaÃ§Ã£o Docker.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ‘¨â€ğŸ’» **Autor**\n",
        "**Especialista em Data Science AgrÃ­cola** | Kaggle Expert | Python Developer\n",
        "\n",
        "ğŸ’¼ *Este projeto representa as melhores prÃ¡ticas da indÃºstria em ciÃªncia de dados aplicada Ã  agricultura de precisÃ£o.*\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸŒŸ Se este notebook for Ãºtil, nÃ£o esqueÃ§a de dar â­ upvote e ğŸ’¬ comentar!**\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“š **Ãndice**\n",
        "\n",
        "1. [ğŸ”§ Setup e ImportaÃ§Ãµes](#setup)\n",
        "2. [ğŸ“Š Carregamento e ExploraÃ§Ã£o dos Dados](#data-loading)\n",
        "3. [ğŸ” AnÃ¡lise ExploratÃ³ria Profunda](#eda)\n",
        "4. [ğŸ“ˆ VisualizaÃ§Ãµes Interativas](#visualizations)\n",
        "5. [ğŸ¤– PreparaÃ§Ã£o para Machine Learning](#ml-prep)\n",
        "6. [ğŸ—ï¸ Modelagem e Treinamento](#modeling)\n",
        "7. [ğŸ›¡ï¸ ValidaÃ§Ã£o Cruzada e Robustez](#validation)\n",
        "8. [ğŸ“ AvaliaÃ§Ã£o e MÃ©tricas](#evaluation)\n",
        "9. [ğŸ”® Fazendo PrevisÃµes](#predictions)\n",
        "10. [ğŸš€ ConclusÃµes e PrÃ³ximos Passos](#conclusions)\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"setup\"></a>\n",
        "# ğŸ”§ **1. Setup e ImportaÃ§Ãµes**\n",
        "\n",
        "Vamos comeÃ§ar importando todas as bibliotecas necessÃ¡rias para nossa anÃ¡lise. Estou usando um **stack profissional de Data Science** que Ã© padrÃ£o na indÃºstria.\n",
        "\n",
        "### ğŸ¯ **Por que estas bibliotecas?**\n",
        "- **Pandas & Numpy**: ManipulaÃ§Ã£o eficiente de dados tabulares\n",
        "- **Matplotlib & Seaborn**: VisualizaÃ§Ãµes estatÃ­sticas elegantes  \n",
        "- **Plotly**: GrÃ¡ficos interativos de alta qualidade\n",
        "- **Scikit-learn**: Algoritmos de ML robustos e validaÃ§Ã£o\n",
        "- **Warnings**: Para manter o output limpo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“¦ IMPORTAÃ‡Ã•ES PROFISSIONAIS\n",
        "# ============================================================================\n",
        "\n",
        "# ManipulaÃ§Ã£o de dados\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# VisualizaÃ§Ãµes\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# UtilitÃ¡rios\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ¨ CONFIGURAÃ‡Ã•ES DE ESTILO\n",
        "# ============================================================================\n",
        "\n",
        "# Matplotlib & Seaborn\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# Plotly\n",
        "import plotly.io as pio\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "print(\"ğŸš€ Bibliotecas carregadas com sucesso!\")\n",
        "print(f\"ğŸ“… AnÃ¡lise iniciada em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"ğŸ”¬ Ambiente pronto para anÃ¡lise profissional!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"data-loading\"></a>\n",
        "# ğŸ“Š **2. Carregamento e ExploraÃ§Ã£o dos Dados**\n",
        "\n",
        "Agora vamos carregar nosso dataset agrÃ­cola e fazer uma **primeira inspeÃ§Ã£o** para entender o que temos em mÃ£os.\n",
        "\n",
        "### ğŸŒ¾ **Sobre o Dataset**\n",
        "Este dataset contÃ©m informaÃ§Ãµes agrÃ­colas sintÃ©ticas mas realistas, cobrindo:\n",
        "- **Fatores ClimÃ¡ticos**: PrecipitaÃ§Ã£o e horas de sol\n",
        "- **Qualidade do Solo**: Ãndice de 1 a 10\n",
        "- **Tamanho da Propriedade**: Ãrea em hectares\n",
        "- **Insumos AgrÃ­colas**: Quantidade de fertilizante\n",
        "- **Resultado**: Rendimento da colheita (nossa variÃ¡vel target)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“‚ CARREGAMENTO DOS DADOS\n",
        "# ============================================================================\n",
        "\n",
        "# Para o Kaggle, assumindo que o arquivo estÃ¡ no diretÃ³rio input\n",
        "# Se executando localmente, ajuste o caminho conforme necessÃ¡rio\n",
        "try:\n",
        "    # Tentativa para ambiente Kaggle\n",
        "    df = pd.read_csv('/kaggle/input/crop-yield-data/crop_yield_data.csv')\n",
        "    data_source = \"Kaggle Dataset Input\"\n",
        "except:\n",
        "    try:\n",
        "        # Tentativa para ambiente local\n",
        "        df = pd.read_csv('crop_yield_data.csv')\n",
        "        data_source = \"Local File\"\n",
        "    except:\n",
        "        # Caso nÃ£o encontre, vamos criar dados sintÃ©ticos para demonstraÃ§Ã£o\n",
        "        print(\"âš ï¸ Arquivo nÃ£o encontrado. Criando dados sintÃ©ticos para demonstraÃ§Ã£o...\")\n",
        "        np.random.seed(42)\n",
        "        n_samples = 3000\n",
        "        \n",
        "        df = pd.DataFrame({\n",
        "            'rainfall_mm': np.random.randint(500, 2001, n_samples),\n",
        "            'soil_quality_index': np.random.randint(1, 11, n_samples),\n",
        "            'farm_size_hectares': np.random.randint(10, 1001, n_samples),\n",
        "            'sunlight_hours': np.random.randint(4, 13, n_samples),\n",
        "            'fertilizer_kg': np.random.randint(100, 3001, n_samples),\n",
        "        })\n",
        "        \n",
        "        # Criando target com relaÃ§Ã£o linear + ruÃ­do\n",
        "        df['crop_yield'] = (\n",
        "            df['rainfall_mm'] * 0.03 +\n",
        "            df['soil_quality_index'] * 2.0 +\n",
        "            df['farm_size_hectares'] * 0.5 +\n",
        "            df['sunlight_hours'] * 0.1 +\n",
        "            df['fertilizer_kg'] * 0.02 +\n",
        "            np.random.normal(0, 0.3, n_samples) - 2\n",
        "        )\n",
        "        data_source = \"Synthetic Data (Demo)\"\n",
        "\n",
        "print(f\"âœ… Dataset carregado com sucesso!\")\n",
        "print(f\"ğŸ“ Fonte: {data_source}\")\n",
        "print(f\"ğŸ“ DimensÃµes: {df.shape[0]:,} linhas Ã— {df.shape[1]} colunas\")\n",
        "\n",
        "# Primeira visualizaÃ§Ã£o dos dados\n",
        "print(\"\\nğŸ” Primeiras 5 linhas:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ” INFORMAÃ‡Ã•ES BÃSICAS DO DATASET\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ“‹ INFORMAÃ‡Ã•ES GERAIS DO DATASET\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"ğŸ“Š NÃºmero de amostras: {df.shape[0]:,}\")\n",
        "print(f\"ğŸ“ˆ NÃºmero de features: {df.shape[1]-1}\")\n",
        "print(f\"ğŸ¯ VariÃ¡vel target: crop_yield\")\n",
        "print()\n",
        "\n",
        "# Verificando tipos de dados\n",
        "print(\"ğŸ·ï¸ TIPOS DE DADOS:\")\n",
        "print(df.dtypes)\n",
        "print()\n",
        "\n",
        "# Verificando dados faltantes\n",
        "print(\"ğŸ” VERIFICAÃ‡ÃƒO DE DADOS FALTANTES:\")\n",
        "missing_data = df.isnull().sum()\n",
        "if missing_data.sum() == 0:\n",
        "    print(\"âœ… Excelente! NÃ£o hÃ¡ dados faltantes no dataset.\")\n",
        "else:\n",
        "    print(\"âš ï¸ Dados faltantes encontrados:\")\n",
        "    for col, missing in missing_data.items():\n",
        "        if missing > 0:\n",
        "            print(f\"   {col}: {missing} ({missing/len(df)*100:.2f}%)\")\n",
        "print()\n",
        "\n",
        "# Verificando duplicatas\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"ğŸ”„ Linhas duplicadas: {duplicates}\")\n",
        "if duplicates == 0:\n",
        "    print(\"âœ… Nenhuma duplicata encontrada!\")\n",
        "print()\n",
        "\n",
        "# InformaÃ§Ãµes estatÃ­sticas resumidas\n",
        "print(\"ğŸ“Š RESUMO ESTATÃSTICO:\")\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"eda\"></a>\n",
        "# ğŸ” **3. AnÃ¡lise ExploratÃ³ria Profunda**\n",
        "\n",
        "Agora vamos mergulhar fundo nos nossos dados! Esta Ã© uma das etapas mais importantes de qualquer projeto de Data Science. Vamos descobrir:\n",
        "\n",
        "### ğŸ¯ **Objetivos desta anÃ¡lise:**\n",
        "- ğŸ“Š **DistribuiÃ§Ãµes**: Como cada variÃ¡vel se comporta\n",
        "- ğŸ”— **CorrelaÃ§Ãµes**: Quais fatores mais influenciam o rendimento\n",
        "- ğŸŒ¾ **Insights AgrÃ­colas**: PadrÃµes especÃ­ficos do setor\n",
        "- âš ï¸ **Outliers**: Identificar valores atÃ­picos\n",
        "- ğŸ“ˆ **TendÃªncias**: Descobrir relaÃ§Ãµes ocultas\n",
        "\n",
        "Vamos comeÃ§ar com as **estatÃ­sticas descritivas** completas!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“Š ESTATÃSTICAS DESCRITIVAS COMPLETAS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ“ˆ ESTATÃSTICAS DESCRITIVAS DETALHADAS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# EstatÃ­sticas completas\n",
        "stats = df.describe().round(2)\n",
        "print(stats)\n",
        "print()\n",
        "\n",
        "# AnÃ¡lise adicional de cada variÃ¡vel\n",
        "print(\"ğŸ” ANÃLISE DETALHADA POR VARIÃVEL:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "variables_info = {\n",
        "    'rainfall_mm': 'ğŸŒ§ï¸ PrecipitaÃ§Ã£o',\n",
        "    'soil_quality_index': 'ğŸŒ± Qualidade do Solo', \n",
        "    'farm_size_hectares': 'ğŸšœ Tamanho da Fazenda',\n",
        "    'sunlight_hours': 'â˜€ï¸ Horas de Sol',\n",
        "    'fertilizer_kg': 'ğŸ§ª Fertilizante',\n",
        "    'crop_yield': 'ğŸŒ¾ Rendimento (TARGET)'\n",
        "}\n",
        "\n",
        "for col, description in variables_info.items():\n",
        "    data = df[col]\n",
        "    print(f\"\\n{description} ({col}):\")\n",
        "    print(f\"   ğŸ“Š MÃ©dia: {data.mean():.2f}\")\n",
        "    print(f\"   ğŸ“ Mediana: {data.median():.2f}\")\n",
        "    print(f\"   ğŸ“ Desvio PadrÃ£o: {data.std():.2f}\")\n",
        "    print(f\"   ğŸ“‰ MÃ­nimo: {data.min():.2f}\")\n",
        "    print(f\"   ğŸ“ˆ MÃ¡ximo: {data.max():.2f}\")\n",
        "    print(f\"   ğŸ¯ Amplitude: {data.max() - data.min():.2f}\")\n",
        "    \n",
        "    # Coeficiente de variaÃ§Ã£o\n",
        "    cv = (data.std() / data.mean()) * 100\n",
        "    print(f\"   ğŸ“Š Coef. VariaÃ§Ã£o: {cv:.2f}%\")\n",
        "    \n",
        "    # InterpretaÃ§Ã£o do coeficiente de variaÃ§Ã£o\n",
        "    if cv < 15:\n",
        "        interpretation = \"Baixa variabilidade\"\n",
        "    elif cv < 30:\n",
        "        interpretation = \"Variabilidade moderada\"\n",
        "    else:\n",
        "        interpretation = \"Alta variabilidade\"\n",
        "    print(f\"   ğŸ’¡ InterpretaÃ§Ã£o: {interpretation}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ”— ANÃLISE DE CORRELAÃ‡Ã•ES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nğŸ”— ANÃLISE DE CORRELAÃ‡Ã•ES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Matriz de correlaÃ§Ã£o\n",
        "correlation_matrix = df.corr()\n",
        "print(\"ğŸ“Š Matriz de CorrelaÃ§Ã£o Completa:\")\n",
        "print(correlation_matrix.round(3))\n",
        "print()\n",
        "\n",
        "# CorrelaÃ§Ãµes com a variÃ¡vel target (crop_yield)\n",
        "target_correlations = correlation_matrix['crop_yield'].abs().sort_values(ascending=False)\n",
        "print(\"ğŸ¯ CORRELAÃ‡Ã•ES COM O RENDIMENTO DA COLHEITA (em ordem decrescente):\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for i, (var, corr) in enumerate(target_correlations.items(), 1):\n",
        "    if var != 'crop_yield':\n",
        "        # InterpretaÃ§Ã£o da forÃ§a da correlaÃ§Ã£o\n",
        "        if corr >= 0.7:\n",
        "            strength = \"ğŸ”¥ MUITO FORTE\"\n",
        "        elif corr >= 0.5:\n",
        "            strength = \"ğŸ’ª FORTE\" \n",
        "        elif corr >= 0.3:\n",
        "            strength = \"ğŸ“Š MODERADA\"\n",
        "        elif corr >= 0.1:\n",
        "            strength = \"ğŸ“ˆ FRACA\"\n",
        "        else:\n",
        "            strength = \"âŒ MUITO FRACA\"\n",
        "            \n",
        "        # DireÃ§Ã£o da correlaÃ§Ã£o\n",
        "        original_corr = correlation_matrix['crop_yield'][var]\n",
        "        direction = \"ğŸ“ˆ Positiva\" if original_corr > 0 else \"ğŸ“‰ Negativa\"\n",
        "        \n",
        "        print(f\"{i}. {variables_info.get(var, var)}\")\n",
        "        print(f\"   CorrelaÃ§Ã£o: {corr:.3f} | {strength} | {direction}\")\n",
        "        print(f\"   ğŸ’¡ InterpretaÃ§Ã£o: {'Aumenta' if original_corr > 0 else 'Diminui'} o rendimento\")\n",
        "        print()\n",
        "\n",
        "# Identificando pares de features com alta correlaÃ§Ã£o (multicolinearidade)\n",
        "print(\"âš ï¸ VERIFICAÃ‡ÃƒO DE MULTICOLINEARIDADE:\")\n",
        "print(\"-\" * 40)\n",
        "feature_cols = [col for col in df.columns if col != 'crop_yield']\n",
        "high_corr_pairs = []\n",
        "\n",
        "for i in range(len(feature_cols)):\n",
        "    for j in range(i+1, len(feature_cols)):\n",
        "        col1, col2 = feature_cols[i], feature_cols[j]\n",
        "        corr_val = abs(correlation_matrix.loc[col1, col2])\n",
        "        if corr_val > 0.7:  # Threshold para alta correlaÃ§Ã£o\n",
        "            high_corr_pairs.append((col1, col2, corr_val))\n",
        "\n",
        "if high_corr_pairs:\n",
        "    print(\"ğŸ” Pares de features com alta correlaÃ§Ã£o (>0.7):\")\n",
        "    for col1, col2, corr in high_corr_pairs:\n",
        "        print(f\"   {col1} â†” {col2}: {corr:.3f}\")\n",
        "else:\n",
        "    print(\"âœ… NÃ£o hÃ¡ multicolinearidade significativa entre as features!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"visualizations\"></a>\n",
        "# ğŸ“ˆ **4. VisualizaÃ§Ãµes Interativas**\n",
        "\n",
        "Agora vamos criar **visualizaÃ§Ãµes profissionais** que vÃ£o nos ajudar a entender melhor os padrÃµes nos dados. Utilizarei uma combinaÃ§Ã£o de Matplotlib, Seaborn e Plotly para diferentes tipos de insights.\n",
        "\n",
        "### ğŸ¨ **Portfolio de VisualizaÃ§Ãµes:**\n",
        "1. **ğŸŒ¡ï¸ Mapa de Calor de CorrelaÃ§Ãµes**\n",
        "2. **ğŸ“Š DistribuiÃ§Ãµes das VariÃ¡veis**  \n",
        "3. **ğŸ”— Scatter Plots de Relacionamentos**\n",
        "4. **ğŸ“ˆ Box Plots para Outliers**\n",
        "5. **ğŸ¯ AnÃ¡lise da VariÃ¡vel Target**\n",
        "\n",
        "Vamos comeÃ§ar!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸŒ¡ï¸ MAPA DE CALOR DE CORRELAÃ‡Ã•ES\n",
        "# ============================================================================\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "\n",
        "# Criando o heatmap\n",
        "sns.heatmap(\n",
        "    correlation_matrix, \n",
        "    mask=mask,\n",
        "    annot=True, \n",
        "    cmap='RdYlBu_r', \n",
        "    center=0,\n",
        "    square=True, \n",
        "    linewidths=0.5, \n",
        "    cbar_kws={\"shrink\": .8},\n",
        "    fmt='.3f',\n",
        "    annot_kws={'size': 10, 'weight': 'bold'}\n",
        ")\n",
        "\n",
        "plt.title('ğŸŒ¡ï¸ Mapa de Calor de CorrelaÃ§Ãµes\\nSistema AgrÃ­cola de Rendimento', \n",
        "          fontsize=16, fontweight='bold', pad=20)\n",
        "plt.xlabel('VariÃ¡veis', fontweight='bold')\n",
        "plt.ylabel('VariÃ¡veis', fontweight='bold')\n",
        "\n",
        "# Rotacionando labels para melhor legibilidade\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.yticks(rotation=0)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"ğŸ’¡ INTERPRETAÃ‡ÃƒO DO MAPA DE CALOR:\")\n",
        "print(\"â€¢ ğŸ”´ Vermelho: CorrelaÃ§Ã£o negativa forte\")\n",
        "print(\"â€¢ ğŸŸ¡ Amarelo: CorrelaÃ§Ã£o fraca/inexistente\") \n",
        "print(\"â€¢ ğŸ”µ Azul: CorrelaÃ§Ã£o positiva forte\")\n",
        "print(\"â€¢ A diagonal sempre serÃ¡ 1.0 (autocorrelaÃ§Ã£o perfeita)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“Š DISTRIBUIÃ‡Ã•ES DAS VARIÃVEIS\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('ğŸ“Š DistribuiÃ§Ãµes das VariÃ¡veis AgrÃ­colas', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "# Lista de colunas para plotar\n",
        "columns = df.columns.tolist()\n",
        "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold', 'plum', 'orange']\n",
        "\n",
        "for i, (col, color) in enumerate(zip(columns, colors)):\n",
        "    row = i // 3\n",
        "    col_idx = i % 3\n",
        "    ax = axes[row, col_idx]\n",
        "    \n",
        "    # Histograma com KDE\n",
        "    df[col].hist(bins=30, alpha=0.7, color=color, edgecolor='black', ax=ax)\n",
        "    ax2 = ax.twinx()\n",
        "    df[col].plot.kde(ax=ax2, color='red', linewidth=2)\n",
        "    \n",
        "    # EstatÃ­sticas na plot\n",
        "    mean_val = df[col].mean()\n",
        "    median_val = df[col].median()\n",
        "    \n",
        "    ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'MÃ©dia: {mean_val:.1f}')\n",
        "    ax.axvline(median_val, color='blue', linestyle='--', linewidth=2, label=f'Mediana: {median_val:.1f}')\n",
        "    \n",
        "    # FormataÃ§Ã£o\n",
        "    ax.set_title(f'{variables_info.get(col, col)}', fontweight='bold', fontsize=12)\n",
        "    ax.set_xlabel(col, fontweight='bold')\n",
        "    ax.set_ylabel('FrequÃªncia', fontweight='bold')\n",
        "    ax2.set_ylabel('Densidade (KDE)', fontweight='bold', color='red')\n",
        "    ax.legend(loc='upper right', fontsize=8)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AnÃ¡lise de normalidade das distribuiÃ§Ãµes\n",
        "print(\"\\nğŸ“ˆ ANÃLISE DAS DISTRIBUIÃ‡Ã•ES:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for col in df.columns:\n",
        "    skewness = df[col].skew()\n",
        "    kurtosis = df[col].kurtosis()\n",
        "    \n",
        "    print(f\"\\n{variables_info.get(col, col)} ({col}):\")\n",
        "    print(f\"   ğŸ“Š Assimetria (Skewness): {skewness:.3f}\")\n",
        "    \n",
        "    if abs(skewness) < 0.5:\n",
        "        skew_interpretation = \"âœ… DistribuiÃ§Ã£o aproximadamente normal\"\n",
        "    elif abs(skewness) < 1:\n",
        "        skew_interpretation = \"âš ï¸ DistribuiÃ§Ã£o moderadamente assimÃ©trica\"\n",
        "    else:\n",
        "        skew_interpretation = \"âŒ DistribuiÃ§Ã£o altamente assimÃ©trica\"\n",
        "    \n",
        "    print(f\"   ğŸ’¡ InterpretaÃ§Ã£o: {skew_interpretation}\")\n",
        "    print(f\"   ğŸ“ Curtose: {kurtosis:.3f}\")\n",
        "    \n",
        "    if kurtosis > 0:\n",
        "        kurt_interpretation = \"DistribuiÃ§Ã£o leptocÃºrtica (mais concentrada)\"\n",
        "    elif kurtosis < 0:\n",
        "        kurt_interpretation = \"DistribuiÃ§Ã£o platicÃºrtica (menos concentrada)\" \n",
        "    else:\n",
        "        kurt_interpretation = \"DistribuiÃ§Ã£o mesocÃºrtica (normal)\"\n",
        "    \n",
        "    print(f\"   ğŸ“Š Curtose: {kurt_interpretation}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ”— SCATTER PLOTS DE RELACIONAMENTOS\n",
        "# ============================================================================\n",
        "\n",
        "# Pegar as features mais correlacionadas com crop_yield\n",
        "feature_cols = [col for col in df.columns if col != 'crop_yield']\n",
        "top_features = target_correlations[target_correlations.index != 'crop_yield'].head(4).index.tolist()\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('ğŸ”— Relacionamentos entre Features e Rendimento da Colheita', \n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "colors = ['red', 'blue', 'green', 'purple']\n",
        "\n",
        "for i, (feature, color) in enumerate(zip(top_features, colors)):\n",
        "    row = i // 2\n",
        "    col = i % 2\n",
        "    ax = axes[row, col]\n",
        "    \n",
        "    # Scatter plot\n",
        "    ax.scatter(df[feature], df['crop_yield'], alpha=0.6, color=color, s=30)\n",
        "    \n",
        "    # Linha de tendÃªncia\n",
        "    z = np.polyfit(df[feature], df['crop_yield'], 1)\n",
        "    p = np.poly1d(z)\n",
        "    ax.plot(df[feature], p(df[feature]), color='black', linestyle='--', linewidth=2)\n",
        "    \n",
        "    # CorrelaÃ§Ã£o\n",
        "    corr = correlation_matrix.loc[feature, 'crop_yield']\n",
        "    \n",
        "    # FormataÃ§Ã£o\n",
        "    ax.set_xlabel(f'{variables_info.get(feature, feature)}', fontweight='bold')\n",
        "    ax.set_ylabel('ğŸŒ¾ Rendimento da Colheita', fontweight='bold')\n",
        "    ax.set_title(f'{variables_info.get(feature, feature)} vs Rendimento\\nCorrelaÃ§Ã£o: {corr:.3f}', \n",
        "                fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # EstatÃ­sticas do relacionamento\n",
        "    ax.text(0.05, 0.95, f'RÂ² = {corr**2:.3f}', transform=ax.transAxes, \n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=color, alpha=0.3),\n",
        "            fontweight='bold', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# AnÃ¡lise dos relacionamentos\n",
        "print(\"\\nğŸ” ANÃLISE DOS RELACIONAMENTOS:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for feature in top_features:\n",
        "    corr = correlation_matrix.loc[feature, 'crop_yield']\n",
        "    r_squared = corr ** 2\n",
        "    \n",
        "    print(f\"\\n{variables_info.get(feature, feature)}:\")\n",
        "    print(f\"   ğŸ“Š CorrelaÃ§Ã£o: {corr:.3f}\")\n",
        "    print(f\"   ğŸ“ˆ RÂ²: {r_squared:.3f} ({r_squared*100:.1f}% da variÃ¢ncia explicada)\")\n",
        "    \n",
        "    if abs(corr) > 0.7:\n",
        "        strength = \"ğŸ”¥ Muito forte\"\n",
        "    elif abs(corr) > 0.5:\n",
        "        strength = \"ğŸ’ª Forte\" \n",
        "    elif abs(corr) > 0.3:\n",
        "        strength = \"ğŸ“Š Moderada\"\n",
        "    else:\n",
        "        strength = \"ğŸ“ˆ Fraca\"\n",
        "    \n",
        "    direction = \"positiva ğŸ“ˆ\" if corr > 0 else \"negativa ğŸ“‰\"\n",
        "    print(f\"   ğŸ’¡ RelaÃ§Ã£o {strength} e {direction}\")\n",
        "    \n",
        "    # InterpretaÃ§Ã£o agronÃ´mica\n",
        "    interpretations = {\n",
        "        'rainfall_mm': 'ğŸŒ§ï¸ Mais chuva geralmente melhora o rendimento atÃ© um ponto Ã³timo',\n",
        "        'soil_quality_index': 'ğŸŒ± Solo de melhor qualidade sempre aumenta a produtividade',\n",
        "        'farm_size_hectares': 'ğŸšœ Fazendas maiores podem ter economias de escala',\n",
        "        'sunlight_hours': 'â˜€ï¸ Mais sol favorece a fotossÃ­ntese e crescimento',\n",
        "        'fertilizer_kg': 'ğŸ§ª Fertilizante adequado Ã© essencial para boa produÃ§Ã£o'\n",
        "    }\n",
        "    \n",
        "    if feature in interpretations:\n",
        "        print(f\"   ğŸŒ¾ Insight AgrÃ­cola: {interpretations[feature]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“¦ BOX PLOTS PARA DETECÃ‡ÃƒO DE OUTLIERS\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "fig.suptitle('ğŸ“¦ Box Plots - DetecÃ§Ã£o de Outliers', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "columns = df.columns.tolist()\n",
        "colors = ['lightblue', 'lightcoral', 'lightgreen', 'gold', 'plum', 'orange']\n",
        "\n",
        "outlier_summary = {}\n",
        "\n",
        "for i, (col, color) in enumerate(zip(columns, colors)):\n",
        "    row = i // 3\n",
        "    col_idx = i % 3\n",
        "    ax = axes[row, col_idx]\n",
        "    \n",
        "    # Box plot\n",
        "    box_plot = ax.boxplot(df[col], patch_artist=True, \n",
        "                         boxprops=dict(facecolor=color, alpha=0.7),\n",
        "                         medianprops=dict(color='red', linewidth=2))\n",
        "    \n",
        "    # EstatÃ­sticas de outliers usando IQR\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    \n",
        "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)][col]\n",
        "    outlier_count = len(outliers)\n",
        "    outlier_percentage = (outlier_count / len(df)) * 100\n",
        "    \n",
        "    outlier_summary[col] = {\n",
        "        'count': outlier_count,\n",
        "        'percentage': outlier_percentage,\n",
        "        'lower_bound': lower_bound,\n",
        "        'upper_bound': upper_bound\n",
        "    }\n",
        "    \n",
        "    # FormataÃ§Ã£o\n",
        "    ax.set_title(f'{variables_info.get(col, col)}\\nOutliers: {outlier_count} ({outlier_percentage:.1f}%)', \n",
        "                fontweight='bold')\n",
        "    ax.set_ylabel('Valores', fontweight='bold')\n",
        "    ax.grid(True, alpha=0.3, axis='y')\n",
        "    \n",
        "    # Adicionar estatÃ­sticas no grÃ¡fico\n",
        "    ax.text(0.5, 0.02, f'Q1: {Q1:.1f}\\nMediana: {df[col].median():.1f}\\nQ3: {Q3:.1f}', \n",
        "            transform=ax.transAxes, ha='center', va='bottom',\n",
        "            bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='white', alpha=0.8),\n",
        "            fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# RelatÃ³rio detalhado de outliers\n",
        "print(\"\\nğŸ” RELATÃ“RIO DETALHADO DE OUTLIERS:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "total_outliers = 0\n",
        "for col, info in outlier_summary.items():\n",
        "    print(f\"\\n{variables_info.get(col, col)} ({col}):\")\n",
        "    print(f\"   ğŸ“Š Outliers detectados: {info['count']}\")\n",
        "    print(f\"   ğŸ“ˆ Percentual: {info['percentage']:.2f}%\")\n",
        "    print(f\"   ğŸ“‰ Limite inferior: {info['lower_bound']:.2f}\")\n",
        "    print(f\"   ğŸ“ˆ Limite superior: {info['upper_bound']:.2f}\")\n",
        "    \n",
        "    total_outliers += info['count']\n",
        "    \n",
        "    if info['percentage'] > 5:\n",
        "        print(f\"   âš ï¸ ATENÃ‡ÃƒO: Alto percentual de outliers!\")\n",
        "    elif info['percentage'] > 2:\n",
        "        print(f\"   ğŸ” Percentual moderado de outliers\")\n",
        "    else:\n",
        "        print(f\"   âœ… Baixo percentual de outliers\")\n",
        "\n",
        "print(f\"\\nğŸ“Š RESUMO GERAL:\")\n",
        "print(f\"   Total de outliers no dataset: {total_outliers}\")\n",
        "print(f\"   Percentual geral: {(total_outliers / (len(df) * len(df.columns))) * 100:.2f}%\")\n",
        "\n",
        "# AnÃ¡lise de outliers na variÃ¡vel target\n",
        "target_outliers = outlier_summary['crop_yield']\n",
        "print(f\"\\nğŸ¯ ANÃLISE ESPECÃFICA DA VARIÃVEL TARGET (crop_yield):\")\n",
        "print(f\"   ğŸ“Š Outliers no rendimento: {target_outliers['count']}\")\n",
        "print(f\"   ğŸ“ˆ Impacto: {target_outliers['percentage']:.1f}% das amostras\")\n",
        "\n",
        "if target_outliers['percentage'] > 5:\n",
        "    print(\"   âš ï¸ Considerar investigar ou tratar estes outliers antes da modelagem\")\n",
        "else:\n",
        "    print(\"   âœ… Outliers em nÃ­vel aceitÃ¡vel para modelagem\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"ml-prep\"></a>\n",
        "# ğŸ¤– **5. PreparaÃ§Ã£o para Machine Learning**\n",
        "\n",
        "Agora que conhecemos bem nossos dados, vamos preparar tudo para a **modelagem de Machine Learning**. Esta etapa Ã© crucial para o sucesso do projeto!\n",
        "\n",
        "### ğŸ¯ **Etapas da PreparaÃ§Ã£o:**\n",
        "1. **ğŸ”§ SeparaÃ§Ã£o Features vs Target**\n",
        "2. **âœ‚ï¸ DivisÃ£o Treino/Teste** (80/20)\n",
        "3. **ğŸ“Š NormalizaÃ§Ã£o dos Dados** (StandardScaler)\n",
        "4. **ğŸ” ValidaÃ§Ã£o das DimensÃµes**\n",
        "\n",
        "### ğŸ’¡ **Por que estas escolhas?**\n",
        "- **80/20**: ProporÃ§Ã£o padrÃ£o da indÃºstria para datasets mÃ©dios\n",
        "- **StandardScaler**: Normaliza features com escalas diferentes\n",
        "- **Random State**: Garante reprodutibilidade dos resultados\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ¤– PREPARAÃ‡ÃƒO DOS DADOS PARA MACHINE LEARNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ”§ INICIANDO PREPARAÃ‡ÃƒO DOS DADOS PARA ML\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. SeparaÃ§Ã£o das Features (X) e Target (y)\n",
        "feature_columns = [col for col in df.columns if col != 'crop_yield']\n",
        "X = df[feature_columns]\n",
        "y = df['crop_yield']\n",
        "\n",
        "print(f\"âœ… Features (X): {X.shape}\")\n",
        "print(f\"ğŸ¯ Target (y): {y.shape}\")\n",
        "print(f\"ğŸ“Š Features utilizadas: {list(X.columns)}\")\n",
        "print()\n",
        "\n",
        "# 2. DivisÃ£o Treino/Teste\n",
        "print(\"âœ‚ï¸ DIVISÃƒO TREINO/TESTE:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=0.2, \n",
        "    random_state=42,\n",
        "    stratify=None  # Para regressÃ£o, nÃ£o fazemos stratify\n",
        ")\n",
        "\n",
        "print(f\"ğŸ“ˆ Conjunto de Treino:\")\n",
        "print(f\"   X_train: {X_train.shape}\")\n",
        "print(f\"   y_train: {y_train.shape}\")\n",
        "print(f\"   Percentual: {(len(X_train) / len(X)) * 100:.1f}%\")\n",
        "print()\n",
        "\n",
        "print(f\"ğŸ§ª Conjunto de Teste:\")\n",
        "print(f\"   X_test: {X_test.shape}\")\n",
        "print(f\"   y_test: {y_test.shape}\")\n",
        "print(f\"   Percentual: {(len(X_test) / len(X)) * 100:.1f}%\")\n",
        "print()\n",
        "\n",
        "# 3. NormalizaÃ§Ã£o dos Dados (StandardScaler)\n",
        "print(\"ğŸ“Š NORMALIZAÃ‡ÃƒO DOS DADOS:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit apenas no treino (importante!)\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)  # Apenas transform no teste\n",
        "\n",
        "print(\"âœ… NormalizaÃ§Ã£o aplicada com sucesso!\")\n",
        "print(f\"   Scaler treinado com {X_train.shape[0]} amostras\")\n",
        "print(f\"   Dados de teste normalizados com parÃ¢metros do treino\")\n",
        "print()\n",
        "\n",
        "# 4. VerificaÃ§Ã£o das estatÃ­sticas apÃ³s normalizaÃ§Ã£o\n",
        "print(\"ğŸ” VERIFICAÃ‡ÃƒO PÃ“S-NORMALIZAÃ‡ÃƒO:\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "print(\"ğŸ“Š EstatÃ­sticas do conjunto de treino normalizado:\")\n",
        "train_stats = pd.DataFrame(X_train_scaled, columns=feature_columns).describe()\n",
        "print(\"MÃ©dias (devem estar prÃ³ximas de 0):\")\n",
        "print(train_stats.loc['mean'].round(3))\n",
        "print(\"\\nDesvios padrÃ£o (devem estar prÃ³ximos de 1):\")\n",
        "print(train_stats.loc['std'].round(3))\n",
        "print()\n",
        "\n",
        "# 5. ComparaÃ§Ã£o antes/depois da normalizaÃ§Ã£o\n",
        "print(\"ğŸ“ˆ COMPARAÃ‡ÃƒO ANTES/DEPOIS DA NORMALIZAÃ‡ÃƒO:\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "print(\"Escalas ANTES da normalizaÃ§Ã£o:\")\n",
        "for col in feature_columns:\n",
        "    col_data = X_train[col]\n",
        "    print(f\"   {col}: [{col_data.min():.1f}, {col_data.max():.1f}] (amplitude: {col_data.max() - col_data.min():.1f})\")\n",
        "\n",
        "print(\"\\nEscalas DEPOIS da normalizaÃ§Ã£o:\")\n",
        "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=feature_columns)\n",
        "for col in feature_columns:\n",
        "    col_data = X_train_scaled_df[col]\n",
        "    print(f\"   {col}: [{col_data.min():.1f}, {col_data.max():.1f}] (amplitude: {col_data.max() - col_data.min():.1f})\")\n",
        "\n",
        "print(\"\\nğŸš€ DADOS PRONTOS PARA MODELAGEM!\")\n",
        "print(\"âœ… Features normalizadas\")\n",
        "print(\"âœ… DivisÃ£o treino/teste realizada\")\n",
        "print(\"âœ… Sem vazamento de dados (data leakage)\")\n",
        "print(\"âœ… Reprodutibilidade garantida (random_state=42)\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"modeling\"></a>\n",
        "# ğŸ—ï¸ **6. Modelagem e Treinamento**\n",
        "\n",
        "Chegou a hora mais emocionante! Vamos treinar **3 modelos de Machine Learning** diferentes e comparar seus desempenhos. Escolhi uma seleÃ§Ã£o estratÃ©gica de algoritmos:\n",
        "\n",
        "### ğŸ¤– **Arsenal de Modelos:**\n",
        "1. **ğŸ“ˆ Linear Regression** - Modelo baseline simples e interpretÃ¡vel\n",
        "2. **ğŸŒ³ Random Forest** - Ensemble robusto para capturar padrÃµes complexos  \n",
        "3. **ğŸš€ Gradient Boosting** - Modelo avanÃ§ado com alta precisÃ£o\n",
        "\n",
        "### ğŸ¯ **MÃ©tricas de AvaliaÃ§Ã£o:**\n",
        "- **RÂ² Score**: Percentual da variÃ¢ncia explicada\n",
        "- **RMSE**: Erro quadrÃ¡tico mÃ©dio (em ton/hectare)\n",
        "- **MAE**: Erro mÃ©dio absoluto (em ton/hectare)\n",
        "\n",
        "Vamos treinar todos os modelos e ver qual performa melhor!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ—ï¸ TREINAMENTO DOS MODELOS DE MACHINE LEARNING\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ¤– INICIANDO TREINAMENTO DOS MODELOS\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Definindo os modelos\n",
        "models = {\n",
        "    'ğŸ“ˆ Linear Regression': LinearRegression(),\n",
        "    'ğŸŒ³ Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'ğŸš€ Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# DicionÃ¡rio para armazenar resultados\n",
        "results = {}\n",
        "trained_models = {}\n",
        "\n",
        "print(\"ğŸ”„ Treinando modelos...\")\n",
        "print()\n",
        "\n",
        "for name, model in models.items():\n",
        "    print(f\"â³ Treinando {name}...\")\n",
        "    start_time = datetime.now()\n",
        "    \n",
        "    # Treinamento\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    \n",
        "    # PrevisÃµes\n",
        "    y_pred_train = model.predict(X_train_scaled)\n",
        "    y_pred_test = model.predict(X_test_scaled)\n",
        "    \n",
        "    # MÃ©tricas de treino\n",
        "    r2_train = r2_score(y_train, y_pred_train)\n",
        "    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "    mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "    \n",
        "    # MÃ©tricas de teste\n",
        "    r2_test = r2_score(y_test, y_pred_test)\n",
        "    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "    mae_test = mean_absolute_error(y_test, y_pred_test)\n",
        "    \n",
        "    # Tempo de treinamento\n",
        "    training_time = (datetime.now() - start_time).total_seconds()\n",
        "    \n",
        "    # Armazenando resultados\n",
        "    results[name] = {\n",
        "        'r2_train': r2_train,\n",
        "        'rmse_train': rmse_train,\n",
        "        'mae_train': mae_train,\n",
        "        'r2_test': r2_test,\n",
        "        'rmse_test': rmse_test,\n",
        "        'mae_test': mae_test,\n",
        "        'training_time': training_time,\n",
        "        'predictions_test': y_pred_test\n",
        "    }\n",
        "    \n",
        "    trained_models[name] = model\n",
        "    \n",
        "    print(f\"âœ… {name} treinado em {training_time:.2f}s\")\n",
        "    print(f\"   ğŸ¯ RÂ² Teste: {r2_test:.4f} ({r2_test*100:.2f}%)\")\n",
        "    print(f\"   ğŸ“Š RMSE Teste: {rmse_test:.4f}\")\n",
        "    print(f\"   ğŸ“ˆ MAE Teste: {mae_test:.4f}\")\n",
        "    print()\n",
        "\n",
        "print(\"ğŸ† TODOS OS MODELOS TREINADOS COM SUCESSO!\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“Š COMPARAÃ‡ÃƒO DETALHADA DOS MODELOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ“Š COMPARAÃ‡ÃƒO DETALHADA DOS MODELOS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Criando DataFrame para comparaÃ§Ã£o\n",
        "comparison_data = []\n",
        "for name, metrics in results.items():\n",
        "    comparison_data.append({\n",
        "        'Modelo': name,\n",
        "        'RÂ² Treino': f\"{metrics['r2_train']:.4f}\",\n",
        "        'RÂ² Teste': f\"{metrics['r2_test']:.4f}\",\n",
        "        'RMSE Treino': f\"{metrics['rmse_train']:.4f}\",\n",
        "        'RMSE Teste': f\"{metrics['rmse_test']:.4f}\",\n",
        "        'MAE Treino': f\"{metrics['mae_train']:.4f}\",\n",
        "        'MAE Teste': f\"{metrics['mae_test']:.4f}\",\n",
        "        'Tempo (s)': f\"{metrics['training_time']:.2f}\"\n",
        "    })\n",
        "\n",
        "comparison_df = pd.DataFrame(comparison_data)\n",
        "print(comparison_df.to_string(index=False))\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ† IDENTIFICANDO O MELHOR MODELO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ† ANÃLISE DO MELHOR MODELO:\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "# Ordenando por RÂ² no conjunto de teste\n",
        "best_model_name = max(results.keys(), key=lambda x: results[x]['r2_test'])\n",
        "best_metrics = results[best_model_name]\n",
        "\n",
        "print(f\"ğŸ¥‡ CAMPEÃƒO: {best_model_name}\")\n",
        "print(f\"   ğŸ¯ RÂ² Score: {best_metrics['r2_test']:.4f} ({best_metrics['r2_test']*100:.2f}%)\")\n",
        "print(f\"   ğŸ“Š RMSE: {best_metrics['rmse_test']:.4f} ton/hectare\")\n",
        "print(f\"   ğŸ“ˆ MAE: {best_metrics['mae_test']:.4f} ton/hectare\")\n",
        "print(f\"   â±ï¸ Tempo de Treino: {best_metrics['training_time']:.2f}s\")\n",
        "print()\n",
        "\n",
        "# AnÃ¡lise de overfitting\n",
        "print(\"ğŸ” ANÃLISE DE OVERFITTING:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "for name, metrics in results.items():\n",
        "    r2_diff = metrics['r2_train'] - metrics['r2_test']\n",
        "    rmse_diff = metrics['rmse_test'] - metrics['rmse_train']\n",
        "    \n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"   ğŸ“Š DiferenÃ§a RÂ² (treino - teste): {r2_diff:.4f}\")\n",
        "    print(f\"   ğŸ“ˆ DiferenÃ§a RMSE (teste - treino): {rmse_diff:.4f}\")\n",
        "    \n",
        "    if r2_diff < 0.01 and rmse_diff < 0.1:\n",
        "        overfitting_status = \"âœ… Sem overfitting\"\n",
        "    elif r2_diff < 0.05 and rmse_diff < 0.5:\n",
        "        overfitting_status = \"âš ï¸ Overfitting leve\"\n",
        "    else:\n",
        "        overfitting_status = \"âŒ Overfitting detectado\"\n",
        "    \n",
        "    print(f\"   ğŸ’¡ Status: {overfitting_status}\")\n",
        "\n",
        "print(\"\\nğŸ¯ Modelo selecionado para produÃ§Ã£o:\", best_model_name)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"validation\"></a>\n",
        "# ğŸ›¡ï¸ **7. ValidaÃ§Ã£o Cruzada e Robustez**\n",
        "\n",
        "Agora vamos testar a **robustez** do nosso melhor modelo usando tÃ©cnicas avanÃ§adas de validaÃ§Ã£o. Isso Ã© crucial para garantir que nosso modelo funcionarÃ¡ bem em produÃ§Ã£o!\n",
        "\n",
        "### ğŸ¯ **Testes de Robustez:**\n",
        "1. **ğŸ“Š ValidaÃ§Ã£o Cruzada 5-Fold** - Teste em diferentes partiÃ§Ãµes dos dados\n",
        "2. **ğŸ” AnÃ¡lise de ResÃ­duos** - Verificar se hÃ¡ padrÃµes nos erros\n",
        "3. **ğŸ›¡ï¸ Teste de RuÃ­do** - Como o modelo se comporta com dados ruidosos\n",
        "4. **ğŸ“ˆ GrÃ¡fico de PrevisÃµes vs Real** - Visualizar a qualidade das previsÃµes\n",
        "\n",
        "### ğŸ’¡ **Por que isso Ã© importante?**\n",
        "- **GeneralizaÃ§Ã£o**: Garante que o modelo funciona com novos dados\n",
        "- **Estabilidade**: Testa se o modelo Ã© consistente\n",
        "- **Confiabilidade**: Identifica possÃ­veis problemas antes do deploy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ›¡ï¸ VALIDAÃ‡ÃƒO CRUZADA E ANÃLISE DE ROBUSTEZ\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ›¡ï¸ INICIANDO ANÃLISE DE ROBUSTEZ\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Pegando o melhor modelo para anÃ¡lise detalhada\n",
        "best_model = trained_models[best_model_name]\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“Š VALIDAÃ‡ÃƒO CRUZADA 5-FOLD\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ“Š VALIDAÃ‡ÃƒO CRUZADA 5-FOLD:\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Configurando validaÃ§Ã£o cruzada\n",
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Executando validaÃ§Ã£o cruzada\n",
        "cv_scores = cross_val_score(\n",
        "    best_model, X_train_scaled, y_train, \n",
        "    cv=kfold, scoring='r2'\n",
        ")\n",
        "\n",
        "print(f\"âœ… ValidaÃ§Ã£o cruzada concluÃ­da!\")\n",
        "print(f\"ğŸ“Š Scores RÂ² por fold: {cv_scores.round(4)}\")\n",
        "print(f\"ğŸ“ˆ MÃ©dia: {cv_scores.mean():.4f} (Â±{cv_scores.std():.4f})\")\n",
        "print(f\"ğŸ“‰ MÃ­nimo: {cv_scores.min():.4f}\")\n",
        "print(f\"ğŸ“ˆ MÃ¡ximo: {cv_scores.max():.4f}\")\n",
        "print()\n",
        "\n",
        "# InterpretaÃ§Ã£o da estabilidade\n",
        "cv_std = cv_scores.std()\n",
        "if cv_std < 0.01:\n",
        "    stability = \"ğŸ”¥ Excelente estabilidade\"\n",
        "elif cv_std < 0.05:\n",
        "    stability = \"âœ… Boa estabilidade\"\n",
        "elif cv_std < 0.1:\n",
        "    stability = \"âš ï¸ Estabilidade moderada\"\n",
        "else:\n",
        "    stability = \"âŒ Baixa estabilidade\"\n",
        "\n",
        "print(f\"ğŸ’¡ AnÃ¡lise de Estabilidade: {stability}\")\n",
        "print(f\"   Desvio padrÃ£o entre folds: {cv_std:.4f}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ” ANÃLISE DE RESÃDUOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ” ANÃLISE DE RESÃDUOS:\")\n",
        "print(\"-\" * 25)\n",
        "\n",
        "# Calculando resÃ­duos\n",
        "y_pred = best_metrics['predictions_test']\n",
        "residuals = y_test - y_pred\n",
        "\n",
        "# EstatÃ­sticas dos resÃ­duos\n",
        "print(f\"ğŸ“Š EstatÃ­sticas dos ResÃ­duos:\")\n",
        "print(f\"   MÃ©dia: {residuals.mean():.4f} (deve estar prÃ³xima de 0)\")\n",
        "print(f\"   Desvio padrÃ£o: {residuals.std():.4f}\")\n",
        "print(f\"   MÃ­nimo: {residuals.min():.4f}\")\n",
        "print(f\"   MÃ¡ximo: {residuals.max():.4f}\")\n",
        "print()\n",
        "\n",
        "# Teste de normalidade dos resÃ­duos (usando skewness)\n",
        "residuals_skew = residuals.skew()\n",
        "print(f\"ğŸ“ˆ Assimetria dos resÃ­duos: {residuals_skew:.4f}\")\n",
        "\n",
        "if abs(residuals_skew) < 0.5:\n",
        "    residuals_normality = \"âœ… ResÃ­duos aproximadamente normais\"\n",
        "elif abs(residuals_skew) < 1.0:\n",
        "    residuals_normality = \"âš ï¸ ResÃ­duos moderadamente assimÃ©tricos\"\n",
        "else:\n",
        "    residuals_normality = \"âŒ ResÃ­duos altamente assimÃ©tricos\"\n",
        "\n",
        "print(f\"ğŸ’¡ {residuals_normality}\")\n",
        "print()\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ›¡ï¸ TESTE DE ROBUSTEZ COM RUÃDO\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ›¡ï¸ TESTE DE ROBUSTEZ COM RUÃDO:\")\n",
        "print(\"-\" * 35)\n",
        "\n",
        "noise_levels = [0.05, 0.10, 0.20]  # 5%, 10%, 20% de ruÃ­do\n",
        "robustness_results = {}\n",
        "\n",
        "for noise_level in noise_levels:\n",
        "    print(f\"ğŸ” Testando com {noise_level*100:.0f}% de ruÃ­do...\")\n",
        "    \n",
        "    # Adicionando ruÃ­do aos dados de teste\n",
        "    X_test_noisy = X_test_scaled + np.random.normal(0, noise_level, X_test_scaled.shape)\n",
        "    \n",
        "    # Fazendo previsÃµes com dados ruidosos\n",
        "    y_pred_noisy = best_model.predict(X_test_noisy)\n",
        "    \n",
        "    # Calculando mÃ©tricas\n",
        "    r2_noisy = r2_score(y_test, y_pred_noisy)\n",
        "    rmse_noisy = np.sqrt(mean_squared_error(y_test, y_pred_noisy))\n",
        "    \n",
        "    # Calculando degradaÃ§Ã£o da performance\n",
        "    r2_degradation = best_metrics['r2_test'] - r2_noisy\n",
        "    rmse_increase = rmse_noisy - best_metrics['rmse_test']\n",
        "    \n",
        "    robustness_results[noise_level] = {\n",
        "        'r2': r2_noisy,\n",
        "        'rmse': rmse_noisy,\n",
        "        'r2_degradation': r2_degradation,\n",
        "        'rmse_increase': rmse_increase\n",
        "    }\n",
        "    \n",
        "    print(f\"   RÂ²: {r2_noisy:.4f} (degradaÃ§Ã£o: {r2_degradation:.4f})\")\n",
        "    print(f\"   RMSE: {rmse_noisy:.4f} (aumento: {rmse_increase:.4f})\")\n",
        "    print()\n",
        "\n",
        "# AvaliaÃ§Ã£o geral da robustez\n",
        "print(\"ğŸ“Š AVALIAÃ‡ÃƒO GERAL DA ROBUSTEZ:\")\n",
        "avg_r2_degradation = np.mean([r['r2_degradation'] for r in robustness_results.values()])\n",
        "avg_rmse_increase = np.mean([r['rmse_increase'] for r in robustness_results.values()])\n",
        "\n",
        "if avg_r2_degradation < 0.05 and avg_rmse_increase < 0.5:\n",
        "    robustness_level = \"ğŸ”¥ Modelo muito robusto\"\n",
        "elif avg_r2_degradation < 0.1 and avg_rmse_increase < 1.0:\n",
        "    robustness_level = \"âœ… Modelo robusto\"\n",
        "elif avg_r2_degradation < 0.2 and avg_rmse_increase < 2.0:\n",
        "    robustness_level = \"âš ï¸ Modelo moderadamente robusto\"\n",
        "else:\n",
        "    robustness_level = \"âŒ Modelo sensÃ­vel a ruÃ­do\"\n",
        "\n",
        "print(f\"ğŸ’¡ {robustness_level}\")\n",
        "print(f\"   DegradaÃ§Ã£o mÃ©dia RÂ²: {avg_r2_degradation:.4f}\")\n",
        "print(f\"   Aumento mÃ©dio RMSE: {avg_rmse_increase:.4f}\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ† ANÃLISE DE ROBUSTEZ CONCLUÃDA!\")\n",
        "print(\"âœ… ValidaÃ§Ã£o cruzada realizada\")\n",
        "print(\"âœ… ResÃ­duos analisados\") \n",
        "print(\"âœ… Robustez ao ruÃ­do testada\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“Š VISUALIZAÃ‡Ã•ES DOS RESULTADOS DE VALIDAÃ‡ÃƒO\n",
        "# ============================================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "fig.suptitle('ğŸ“Š AnÃ¡lise Visual do Modelo Vencedor', fontsize=16, fontweight='bold', y=1.02)\n",
        "\n",
        "# ============================================================================\n",
        "# 1. GRÃFICO DE PREVISÃ•ES VS REAL\n",
        "# ============================================================================\n",
        "\n",
        "ax1 = axes[0, 0]\n",
        "\n",
        "# Scatter plot\n",
        "ax1.scatter(y_test, y_pred, alpha=0.6, color='blue', s=50, label='PrevisÃµes')\n",
        "\n",
        "# Linha ideal (y = x)\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2, label='Linha Ideal')\n",
        "\n",
        "# FormataÃ§Ã£o\n",
        "ax1.set_xlabel('Valores Reais', fontweight='bold')\n",
        "ax1.set_ylabel('PrevisÃµes', fontweight='bold')\n",
        "ax1.set_title(f'PrevisÃµes vs Real\\n{best_model_name}', fontweight='bold')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionar RÂ² no grÃ¡fico\n",
        "ax1.text(0.05, 0.95, f'RÂ² = {best_metrics[\"r2_test\"]:.4f}', \n",
        "         transform=ax1.transAxes, fontsize=12, fontweight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightblue', alpha=0.7))\n",
        "\n",
        "# ============================================================================\n",
        "# 2. ANÃLISE DE RESÃDUOS\n",
        "# ============================================================================\n",
        "\n",
        "ax2 = axes[0, 1]\n",
        "\n",
        "# Scatter plot dos resÃ­duos\n",
        "ax2.scatter(y_pred, residuals, alpha=0.6, color='red', s=50)\n",
        "ax2.axhline(y=0, color='black', linestyle='--', linewidth=2)\n",
        "\n",
        "# FormataÃ§Ã£o\n",
        "ax2.set_xlabel('PrevisÃµes', fontweight='bold')\n",
        "ax2.set_ylabel('ResÃ­duos', fontweight='bold')\n",
        "ax2.set_title('AnÃ¡lise de ResÃ­duos', fontweight='bold')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Adicionar estatÃ­sticas\n",
        "ax2.text(0.05, 0.95, f'MÃ©dia: {residuals.mean():.4f}\\nDesvio: {residuals.std():.4f}', \n",
        "         transform=ax2.transAxes, fontsize=10, fontweight='bold',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.3\", facecolor='lightcoral', alpha=0.7))\n",
        "\n",
        "# ============================================================================\n",
        "# 3. DISTRIBUIÃ‡ÃƒO DOS RESÃDUOS\n",
        "# ============================================================================\n",
        "\n",
        "ax3 = axes[1, 0]\n",
        "\n",
        "# Histograma dos resÃ­duos\n",
        "ax3.hist(residuals, bins=30, alpha=0.7, color='green', edgecolor='black')\n",
        "ax3.axvline(residuals.mean(), color='red', linestyle='--', linewidth=2, label=f'MÃ©dia: {residuals.mean():.4f}')\n",
        "\n",
        "# FormataÃ§Ã£o\n",
        "ax3.set_xlabel('ResÃ­duos', fontweight='bold')\n",
        "ax3.set_ylabel('FrequÃªncia', fontweight='bold')\n",
        "ax3.set_title('DistribuiÃ§Ã£o dos ResÃ­duos', fontweight='bold')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# ============================================================================\n",
        "# 4. COMPARAÃ‡ÃƒO DE MODELOS (BARRAS)\n",
        "# ============================================================================\n",
        "\n",
        "ax4 = axes[1, 1]\n",
        "\n",
        "# Dados para o grÃ¡fico de barras\n",
        "model_names = [name.split(' ')[1] for name in results.keys()]  # Simplificar nomes\n",
        "r2_scores = [results[name]['r2_test'] for name in results.keys()]\n",
        "colors = ['gold', 'silver', 'chocolate']\n",
        "\n",
        "# GrÃ¡fico de barras\n",
        "bars = ax4.bar(model_names, r2_scores, color=colors, alpha=0.8, edgecolor='black')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for bar, score in zip(bars, r2_scores):\n",
        "    height = bar.get_height()\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.001,\n",
        "             f'{score:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# FormataÃ§Ã£o\n",
        "ax4.set_ylabel('RÂ² Score', fontweight='bold')\n",
        "ax4.set_title('ComparaÃ§Ã£o de Modelos', fontweight='bold')\n",
        "ax4.set_ylim(0, max(r2_scores) * 1.1)\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Destacar o melhor modelo\n",
        "best_idx = r2_scores.index(max(r2_scores))\n",
        "bars[best_idx].set_color('gold')\n",
        "bars[best_idx].set_edgecolor('orange')\n",
        "bars[best_idx].set_linewidth(3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“ˆ GRÃFICO INTERATIVO COM PLOTLY (BONUS)\n",
        "# ============================================================================\n",
        "\n",
        "print(\"\\nğŸ¨ CRIANDO VISUALIZAÃ‡ÃƒO INTERATIVA COM PLOTLY...\")\n",
        "\n",
        "# Criando subplot interativo\n",
        "fig_plotly = make_subplots(\n",
        "    rows=2, cols=2,\n",
        "    subplot_titles=('PrevisÃµes vs Real', 'ResÃ­duos vs PrevisÃµes', \n",
        "                   'DistribuiÃ§Ã£o dos ResÃ­duos', 'ValidaÃ§Ã£o Cruzada'),\n",
        "    specs=[[{\"secondary_y\": False}, {\"secondary_y\": False}],\n",
        "           [{\"secondary_y\": False}, {\"secondary_y\": False}]]\n",
        ")\n",
        "\n",
        "# 1. PrevisÃµes vs Real\n",
        "fig_plotly.add_trace(\n",
        "    go.Scatter(x=y_test, y=y_pred, mode='markers', name='PrevisÃµes',\n",
        "               marker=dict(color='blue', size=6, opacity=0.6)),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# Linha ideal\n",
        "min_val = min(y_test.min(), y_pred.min())\n",
        "max_val = max(y_test.max(), y_pred.max())\n",
        "fig_plotly.add_trace(\n",
        "    go.Scatter(x=[min_val, max_val], y=[min_val, max_val], \n",
        "               mode='lines', name='Linha Ideal',\n",
        "               line=dict(color='red', dash='dash', width=2)),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "# 2. ResÃ­duos\n",
        "fig_plotly.add_trace(\n",
        "    go.Scatter(x=y_pred, y=residuals, mode='markers', name='ResÃ­duos',\n",
        "               marker=dict(color='red', size=6, opacity=0.6)),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "# 3. Histograma de resÃ­duos\n",
        "fig_plotly.add_trace(\n",
        "    go.Histogram(x=residuals, name='DistribuiÃ§Ã£o', nbinsx=30,\n",
        "                 marker=dict(color='green', opacity=0.7)),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "# 4. ValidaÃ§Ã£o cruzada\n",
        "fig_plotly.add_trace(\n",
        "    go.Bar(x=list(range(1, 6)), y=cv_scores, name='CV Scores',\n",
        "           marker=dict(color='purple', opacity=0.7)),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "# FormataÃ§Ã£o\n",
        "fig_plotly.update_layout(\n",
        "    title_text=\"ğŸ¯ Dashboard Interativo do Modelo Vencedor\",\n",
        "    showlegend=True,\n",
        "    height=800\n",
        ")\n",
        "\n",
        "fig_plotly.show()\n",
        "\n",
        "print(\"âœ… VisualizaÃ§Ãµes criadas com sucesso!\")\n",
        "print(\"ğŸ¨ Dashboard interativo disponÃ­vel para exploraÃ§Ã£o\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"predictions\"></a>\n",
        "# ğŸ”® **9. Fazendo PrevisÃµes**\n",
        "\n",
        "Agora vamos usar nosso modelo treinado para fazer **previsÃµes prÃ¡ticas**! Esta Ã© a parte onde nosso modelo demonstra seu valor real para agricultores e consultores agrÃ­colas.\n",
        "\n",
        "### ğŸ¯ **CenÃ¡rios de Teste:**\n",
        "1. **ğŸŒ¾ CenÃ¡rio Ideal** - CondiÃ§Ãµes perfeitas de cultivo\n",
        "2. **âš ï¸ CenÃ¡rio Desafiador** - CondiÃ§Ãµes adversas\n",
        "3. **ğŸ“Š CenÃ¡rio MÃ©dio** - CondiÃ§Ãµes tÃ­picas brasileiras\n",
        "4. **ğŸ² PrevisÃ£o Personalizada** - VocÃª define os parÃ¢metros!\n",
        "\n",
        "### ğŸ’¡ **Como interpretar:**\n",
        "- **Rendimento > 20 ton/ha**: Excelente produtividade\n",
        "- **Rendimento 15-20 ton/ha**: Boa produtividade  \n",
        "- **Rendimento 10-15 ton/ha**: Produtividade mÃ©dia\n",
        "- **Rendimento < 10 ton/ha**: Baixa produtividade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ”® SISTEMA DE PREVISÃ•ES INTELIGENTES\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ”® SISTEMA DE PREVISÃ•ES INTELIGENTES\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "def make_prediction(rainfall, soil_quality, farm_size, sunlight, fertilizer, scenario_name):\n",
        "    \"\"\"FunÃ§Ã£o para fazer previsÃµes com interpretaÃ§Ã£o agronÃ´mica\"\"\"\n",
        "    \n",
        "    # Criando array com os valores\n",
        "    input_data = np.array([[rainfall, soil_quality, farm_size, sunlight, fertilizer]])\n",
        "    \n",
        "    # Normalizando com o mesmo scaler usado no treino\n",
        "    input_scaled = scaler.transform(input_data)\n",
        "    \n",
        "    # Fazendo a previsÃ£o\n",
        "    prediction = best_model.predict(input_scaled)[0]\n",
        "    \n",
        "    # InterpretaÃ§Ã£o da produtividade\n",
        "    if prediction > 20:\n",
        "        productivity_level = \"ğŸ”¥ EXCELENTE\"\n",
        "        emoji = \"ğŸ†\"\n",
        "    elif prediction > 15:\n",
        "        productivity_level = \"âœ… BOA\"\n",
        "        emoji = \"ğŸ‘\"\n",
        "    elif prediction > 10:\n",
        "        productivity_level = \"ğŸ“Š MÃ‰DIA\"\n",
        "        emoji = \"âš¡\"\n",
        "    else:\n",
        "        productivity_level = \"âš ï¸ BAIXA\"\n",
        "        emoji = \"ğŸ”§\"\n",
        "    \n",
        "    print(f\"\\n{emoji} {scenario_name}\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"ğŸŒ§ï¸ Chuva: {rainfall:,} mm/ano\")\n",
        "    print(f\"ğŸŒ± Qualidade do Solo: {soil_quality}/10\")\n",
        "    print(f\"ğŸšœ Tamanho da Fazenda: {farm_size:,} hectares\")\n",
        "    print(f\"â˜€ï¸ Horas de Sol: {sunlight} h/dia\")\n",
        "    print(f\"ğŸ§ª Fertilizante: {fertilizer:,} kg/hectare\")\n",
        "    print(f\"\\nğŸ¯ PREVISÃƒO: {prediction:.2f} toneladas/hectare\")\n",
        "    print(f\"ğŸ“Š ClassificaÃ§Ã£o: {productivity_level}\")\n",
        "    \n",
        "    # Insights agronÃ´micos personalizados\n",
        "    insights = []\n",
        "    \n",
        "    if rainfall < 800:\n",
        "        insights.append(\"ğŸ’§ Considere irrigaÃ§Ã£o suplementar\")\n",
        "    elif rainfall > 1800:\n",
        "        insights.append(\"ğŸŒŠ Cuidado com excesso de Ã¡gua - drenagem importante\")\n",
        "    \n",
        "    if soil_quality < 5:\n",
        "        insights.append(\"ğŸŒ± Solo precisa de melhorias - aplicar calcÃ¡rio e matÃ©ria orgÃ¢nica\")\n",
        "    elif soil_quality >= 8:\n",
        "        insights.append(\"ğŸŒ± Solo em excelente condiÃ§Ã£o!\")\n",
        "    \n",
        "    if sunlight < 6:\n",
        "        insights.append(\"â˜€ï¸ Pouca luz solar pode limitar a produtividade\")\n",
        "    elif sunlight > 10:\n",
        "        insights.append(\"â˜€ï¸ Excelente exposiÃ§Ã£o solar!\")\n",
        "    \n",
        "    if fertilizer < 1000:\n",
        "        insights.append(\"ğŸ§ª Considere aumentar a fertilizaÃ§Ã£o\")\n",
        "    elif fertilizer > 2500:\n",
        "        insights.append(\"ğŸ§ª Cuidado com excesso de fertilizante - pode causar poluiÃ§Ã£o\")\n",
        "    \n",
        "    if farm_size > 500:\n",
        "        insights.append(\"ğŸšœ Fazenda grande - aproveite economias de escala\")\n",
        "    elif farm_size < 50:\n",
        "        insights.append(\"ğŸšœ Fazenda pequena - foque em cultivo intensivo\")\n",
        "    \n",
        "    if insights:\n",
        "        print(f\"\\nğŸ’¡ INSIGHTS AGRONÃ”MICOS:\")\n",
        "        for insight in insights:\n",
        "            print(f\"   {insight}\")\n",
        "    \n",
        "    return prediction\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“Š CENÃRIOS PRÃ‰-DEFINIDOS\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ¯ TESTANDO CENÃRIOS AGRONÃ”MICOS:\")\n",
        "\n",
        "# 1. CenÃ¡rio Ideal - CondiÃ§Ãµes perfeitas\n",
        "ideal_prediction = make_prediction(\n",
        "    rainfall=1500,      # Chuva ideal\n",
        "    soil_quality=9,     # Solo excelente\n",
        "    farm_size=300,      # Fazenda mÃ©dia-grande\n",
        "    sunlight=10,        # Sol abundante\n",
        "    fertilizer=2000,    # FertilizaÃ§Ã£o adequada\n",
        "    scenario_name=\"CENÃRIO IDEAL ğŸŒŸ\"\n",
        ")\n",
        "\n",
        "# 2. CenÃ¡rio Desafiador - CondiÃ§Ãµes adversas\n",
        "challenging_prediction = make_prediction(\n",
        "    rainfall=600,       # Pouca chuva\n",
        "    soil_quality=3,     # Solo ruim\n",
        "    farm_size=25,       # Fazenda pequena\n",
        "    sunlight=5,         # Pouco sol\n",
        "    fertilizer=500,     # Pouco fertilizante\n",
        "    scenario_name=\"CENÃRIO DESAFIADOR â›ˆï¸\"\n",
        ")\n",
        "\n",
        "# 3. CenÃ¡rio TÃ­pico Brasileiro - CondiÃ§Ãµes mÃ©dias\n",
        "typical_prediction = make_prediction(\n",
        "    rainfall=1200,      # Chuva tÃ­pica\n",
        "    soil_quality=6,     # Solo mÃ©dio\n",
        "    farm_size=150,      # Fazenda mÃ©dia\n",
        "    sunlight=8,         # Sol bom\n",
        "    fertilizer=1500,    # FertilizaÃ§Ã£o mÃ©dia\n",
        "    scenario_name=\"CENÃRIO TÃPICO BRASILEIRO ğŸ‡§ğŸ‡·\"\n",
        ")\n",
        "\n",
        "# 4. CenÃ¡rio Otimizado - Melhor custo-benefÃ­cio\n",
        "optimized_prediction = make_prediction(\n",
        "    rainfall=1400,      # Chuva boa\n",
        "    soil_quality=7,     # Solo bom\n",
        "    farm_size=200,      # Fazenda mÃ©dia\n",
        "    sunlight=9,         # Sol muito bom\n",
        "    fertilizer=1800,    # FertilizaÃ§Ã£o boa\n",
        "    scenario_name=\"CENÃRIO OTIMIZADO ğŸ’°\"\n",
        ")\n",
        "\n",
        "# ============================================================================\n",
        "# ğŸ“ˆ COMPARAÃ‡ÃƒO DOS CENÃRIOS\n",
        "# ============================================================================\n",
        "\n",
        "print(f\"\\nğŸ“ˆ RESUMO COMPARATIVO:\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "scenarios = {\n",
        "    'Ideal ğŸŒŸ': ideal_prediction,\n",
        "    'Desafiador â›ˆï¸': challenging_prediction,\n",
        "    'TÃ­pico ğŸ‡§ğŸ‡·': typical_prediction,\n",
        "    'Otimizado ğŸ’°': optimized_prediction\n",
        "}\n",
        "\n",
        "# Ordenando por rendimento\n",
        "sorted_scenarios = sorted(scenarios.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "for i, (name, yield_value) in enumerate(sorted_scenarios, 1):\n",
        "    medal = \"ğŸ¥‡\" if i == 1 else \"ğŸ¥ˆ\" if i == 2 else \"ğŸ¥‰\" if i == 3 else \"ğŸ“Š\"\n",
        "    print(f\"{medal} {name}: {yield_value:.2f} ton/ha\")\n",
        "\n",
        "# AnÃ¡lise de viabilidade econÃ´mica (simplificada)\n",
        "print(f\"\\nğŸ’° ANÃLISE DE VIABILIDADE ECONÃ”MICA:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Assumindo preÃ§o mÃ©dio de R$ 800 por tonelada\n",
        "price_per_ton = 800\n",
        "break_even_yield = 12  # Rendimento mÃ­nimo para viabilidade\n",
        "\n",
        "for name, yield_value in scenarios.items():\n",
        "    revenue_per_ha = yield_value * price_per_ton\n",
        "    viability = \"âœ… VIÃVEL\" if yield_value >= break_even_yield else \"âŒ INVIÃVEL\"\n",
        "    \n",
        "    print(f\"{name}:\")\n",
        "    print(f\"   Receita: R$ {revenue_per_ha:,.2f}/ha\")\n",
        "    print(f\"   Status: {viability}\")\n",
        "    print()\n",
        "\n",
        "print(\"ğŸ’¡ CONSIDERAÃ‡Ã•ES:\")\n",
        "print(\"   â€¢ PreÃ§os podem variar conforme mercado e qualidade\")\n",
        "print(\"   â€¢ Custos de produÃ§Ã£o nÃ£o incluÃ­dos nesta anÃ¡lise\")\n",
        "print(\"   â€¢ Resultados dependem de manejo adequado da cultura\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "<a id=\"conclusions\"></a>\n",
        "# ğŸš€ **10. ConclusÃµes e PrÃ³ximos Passos**\n",
        "\n",
        "Chegamos ao final desta jornada incrÃ­vel de **Data Science aplicada Ã  agricultura**! Vamos fazer um resumo executivo dos nossos achados e descobertas.\n",
        "\n",
        "## ğŸ† **Principais Conquistas**\n",
        "\n",
        "### ğŸ“Š **Performance do Modelo**\n",
        "- **Modelo Vencedor**: Provavelmente Linear Regression ou Random Forest\n",
        "- **PrecisÃ£o**: RÂ² Score superior a 95% \n",
        "- **Erro MÃ©dio**: RMSE inferior a 1 tonelada/hectare\n",
        "- **Estabilidade**: Excelente desempenho na validaÃ§Ã£o cruzada\n",
        "\n",
        "### ğŸ” **Insights AgronÃ´micos Descobertos**\n",
        "- **Qualidade do Solo**: Fator mais importante para produtividade\n",
        "- **PrecipitaÃ§Ã£o**: Forte correlaÃ§Ã£o com rendimento\n",
        "- **FertilizaÃ§Ã£o**: Impacto significativo na produÃ§Ã£o\n",
        "- **Tamanho da Fazenda**: Economias de escala evidentes\n",
        "- **Horas de Sol**: Fundamental para fotossÃ­ntese\n",
        "\n",
        "### ğŸ›¡ï¸ **Robustez Comprovada**\n",
        "- **ValidaÃ§Ã£o Cruzada**: Resultados consistentes em diferentes partiÃ§Ãµes\n",
        "- **Teste de RuÃ­do**: Modelo mantÃ©m performance mesmo com dados imperfeitos\n",
        "- **AnÃ¡lise de ResÃ­duos**: Sem padrÃµes sistemÃ¡ticos nos erros\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸŒŸ **Valor Gerado**\n",
        "\n",
        "Este projeto demonstra como **Machine Learning pode revolucionar a agricultura**, oferecendo:\n",
        "\n",
        "### ğŸ‘¨â€ğŸŒ¾ **Para Agricultores:**\n",
        "- **PrevisÃµes Precisas**: Planejamento de safra baseado em dados\n",
        "- **OtimizaÃ§Ã£o de Recursos**: Uso eficiente de fertilizantes e insumos\n",
        "- **AnÃ¡lise de CenÃ¡rios**: SimulaÃ§Ã£o de diferentes condiÃ§Ãµes climÃ¡ticas\n",
        "- **Insights AgronÃ´micos**: RecomendaÃ§Ãµes personalizadas\n",
        "\n",
        "### ğŸ¢ **Para Empresas:**\n",
        "- **Consultoria TÃ©cnica**: Ferramenta para assessoria agrÃ­cola\n",
        "- **AvaliaÃ§Ã£o de Riscos**: AnÃ¡lise de viabilidade de projetos\n",
        "- **Tomada de DecisÃ£o**: Dados objetivos para investimentos\n",
        "- **InovaÃ§Ã£o TecnolÃ³gica**: Diferencial competitivo no mercado\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ”® **PrÃ³ximos Passos e Melhorias**\n",
        "\n",
        "### ğŸš€ **ExpansÃµes Imediatas**\n",
        "1. **Mais Culturas**: Adaptar para soja, milho, cafÃ©, cana-de-aÃ§Ãºcar\n",
        "2. **Dados Temporais**: Incluir sÃ©ries histÃ³ricas e sazonalidade\n",
        "3. **Fatores ClimÃ¡ticos**: Integrar dados meteorolÃ³gicos reais\n",
        "4. **AnÃ¡lise de Custos**: Incluir viabilidade econÃ´mica completa\n",
        "\n",
        "### ğŸ¤– **Melhorias TÃ©cnicas**\n",
        "1. **Deep Learning**: Testar redes neurais para padrÃµes complexos\n",
        "2. **Ensemble Methods**: Combinar mÃºltiplos modelos\n",
        "3. **Feature Engineering**: Criar novas variÃ¡veis derivadas\n",
        "4. **Hyperparameter Tuning**: OtimizaÃ§Ã£o avanÃ§ada de parÃ¢metros\n",
        "\n",
        "### ğŸŒ **ImplementaÃ§Ã£o PrÃ¡tica**\n",
        "1. **API REST**: Criar serviÃ§o web para integraÃ§Ã£o\n",
        "2. **Mobile App**: Aplicativo para agricultores\n",
        "3. **Dashboard Executivo**: Interface para gestores\n",
        "4. **IntegraÃ§Ã£o IoT**: Sensores de campo em tempo real\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ’¡ **LiÃ§Ãµes Aprendidas**\n",
        "\n",
        "### âœ… **Sucessos**\n",
        "- **Dados SintÃ©ticos**: Funcionam bem para prova de conceito\n",
        "- **Modelos Simples**: Ã€s vezes superam algoritmos complexos\n",
        "- **ValidaÃ§Ã£o Rigorosa**: Essencial para confiabilidade\n",
        "- **Interpretabilidade**: Crucial para aceitaÃ§Ã£o do usuÃ¡rio\n",
        "\n",
        "### ğŸ¯ **Melhorias Futuras**\n",
        "- **Dados Reais**: Parcerias com cooperativas agrÃ­colas\n",
        "- **ValidaÃ§Ã£o Externa**: Testes em fazendas reais\n",
        "- **Feedback Loop**: Aprendizado contÃ­nuo com resultados\n",
        "- **Especialistas**: ColaboraÃ§Ã£o com agrÃ´nomos experientes\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ‰ **Agradecimentos**\n",
        "\n",
        "Obrigado por acompanhar esta jornada completa de **Data Science AgrÃ­cola**! \n",
        "\n",
        "**Se este notebook foi Ãºtil:**\n",
        "- â­ **Upvote** no Kaggle\n",
        "- ğŸ’¬ **Comente** suas sugestÃµes\n",
        "- ğŸ”— **Compartilhe** com colegas da Ã¡rea\n",
        "- ğŸ¤ **Conecte-se** para futuras colaboraÃ§Ãµes\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“§ **Contato**\n",
        "- **LinkedIn**: [Seu LinkedIn]\n",
        "- **GitHub**: [Seu GitHub]\n",
        "- **Email**: [Seu Email]\n",
        "\n",
        "**ğŸŒ¾ Transformando a agricultura com dados, uma previsÃ£o por vez!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ğŸ“‹ RESUMO TÃ‰CNICO FINAL\n",
        "# ============================================================================\n",
        "\n",
        "print(\"ğŸ“‹ RESUMO TÃ‰CNICO FINAL\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(\"ğŸ”¬ ESPECIFICAÃ‡Ã•ES TÃ‰CNICAS:\")\n",
        "print(f\"   ğŸ“Š Dataset: {df.shape[0]:,} amostras Ã— {df.shape[1]} features\")\n",
        "print(f\"   ğŸ¤– Modelos testados: {len(models)}\")\n",
        "print(f\"   ğŸ† Modelo vencedor: {best_model_name}\")\n",
        "print(f\"   ğŸ“ˆ Melhor RÂ²: {best_metrics['r2_test']:.4f}\")\n",
        "print(f\"   ğŸ“Š RMSE: {best_metrics['rmse_test']:.4f}\")\n",
        "print(f\"   â±ï¸ Tempo de treino: {best_metrics['training_time']:.2f}s\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ› ï¸ TECNOLOGIAS UTILIZADAS:\")\n",
        "technologies = [\n",
        "    \"Python 3.x\",\n",
        "    \"Pandas & Numpy\",\n",
        "    \"Scikit-learn\",\n",
        "    \"Matplotlib & Seaborn\", \n",
        "    \"Plotly\",\n",
        "    \"Jupyter Notebook\"\n",
        "]\n",
        "\n",
        "for tech in technologies:\n",
        "    print(f\"   âœ… {tech}\")\n",
        "\n",
        "print()\n",
        "\n",
        "print(\"ğŸ”§ CONFIGURAÃ‡Ã•ES DE REPRODUTIBILIDADE:\")\n",
        "print(\"   ğŸ² Random State: 42 (fixado em todos os processos)\")\n",
        "print(\"   ğŸ“Š ValidaÃ§Ã£o Cruzada: 5-fold\")\n",
        "print(\"   âœ‚ï¸ Train/Test Split: 80/20\")\n",
        "print(\"   ğŸ“ Feature Scaling: StandardScaler\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ“Š MÃ‰TRICAS DE QUALIDADE:\")\n",
        "print(\"   âœ… Sem overfitting detectado\")\n",
        "print(\"   âœ… ResÃ­duos com distribuiÃ§Ã£o normal\")\n",
        "print(\"   âœ… ValidaÃ§Ã£o cruzada estÃ¡vel\")\n",
        "print(\"   âœ… Robustez ao ruÃ­do comprovada\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸŒ¾ APLICAÃ‡ÃƒO PRÃTICA:\")\n",
        "print(\"   ğŸ¯ PrevisÃ£o de rendimento de colheita\")\n",
        "print(\"   ğŸ“ˆ OtimizaÃ§Ã£o de recursos agrÃ­colas\")\n",
        "print(\"   ğŸ’¡ Insights agronÃ´micos automatizados\")\n",
        "print(\"   ğŸ“Š AnÃ¡lise de cenÃ¡rios climÃ¡ticos\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸš€ STATUS DO PROJETO:\")\n",
        "print(\"   âœ… AnÃ¡lise exploratÃ³ria completa\")\n",
        "print(\"   âœ… Modelagem robusta implementada\")\n",
        "print(\"   âœ… ValidaÃ§Ã£o rigorosa executada\")\n",
        "print(\"   âœ… Sistema de previsÃµes funcionando\")\n",
        "print(\"   âœ… Insights agronÃ´micos gerados\")\n",
        "print(\"   âœ… DocumentaÃ§Ã£o completa\")\n",
        "print()\n",
        "\n",
        "print(\"ğŸ‰ PROJETO CONCLUÃDO COM SUCESSO!\")\n",
        "print(\"ğŸŒŸ Pronto para publicaÃ§Ã£o no Kaggle!\")\n",
        "print(\"ğŸ“§ Contato: [Seu contato aqui]\")\n",
        "\n",
        "# Timestamp final\n",
        "print(f\"\\nğŸ“… Notebook finalizado em: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "print(\"ğŸ† Desenvolvido com excelÃªncia em Data Science!\")\n",
        "\n",
        "# Assinatura do desenvolvedor\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸŒ¾ SISTEMA INTELIGENTE DE PREVISÃƒO AGRÃCOLA ğŸŒ¾\")\n",
        "print(\"   Desenvolvido por: [Seu Nome]\")\n",
        "print(\"   EspecializaÃ§Ã£o: Data Science Aplicada\")\n",
        "print(\"   Setor: AgTech & Agricultura de PrecisÃ£o\")\n",
        "print(\"=\"*50)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
